{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции\n",
    "def check_for_none(x):\n",
    "    if x is None:\n",
    "        return ''\n",
    "    else:\n",
    "        return x.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции для Скрапинга\n",
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'ua_file.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_proxy = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.avito.ru'\n",
    "delays = [7, 4, 6, 10, 5, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страница 10 успешно обработана\n",
      "Страница 20 успешно обработана\n",
      "Страница 30 успешно обработана\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,101):\n",
    "    add_url = '/rossiya/avtomobili?p='+str(i)\n",
    "    \n",
    "    final_data = []\n",
    "    pred_ap = {}\n",
    "    if i%10 == 0:\n",
    "        print(f'Страница {i} успешно обработана')\n",
    "    # Короткий текст объявления в шаблоне поиска\n",
    "    url = main_url + add_url\n",
    "    user_agent = get_random_ua()\n",
    "    headers = { 'user-agent': user_agent}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    ap = soup.findAll('div', {'class': 'snippet-horizontal'})\n",
    "    for a in ap:  \n",
    "        delay = np.random.choice(delays)\n",
    "        time.sleep(delay)\n",
    "        pred_ap['main_title'] = check_for_none(a.find('div', {'class': 'snippet-title-row'}))\n",
    "        pred_ap['price_comment'] = check_for_none(a.find('span', {'class': 'snippet-tag'}))\n",
    "        pred_ap['price'] = check_for_none(a.find('span', {'class': 'snippet-price'}))\n",
    "        pred_ap['specific-params'] = check_for_none(a.find('div', {'class': 'specific-params_block'}))\n",
    "        pred_ap['address'] = check_for_none(a.find('div', {'class': 'item-address'}))\n",
    "\n",
    "        ########################################################################\n",
    "        # Полный текст внутри объявления\n",
    "        full_app_dict = {}\n",
    "\n",
    "        url = main_url + a.find('a', {'class': 'snippet-link'}, href=True)['href']\n",
    "        \n",
    "        user_agent = get_random_ua()\n",
    "        headers = { 'user-agent': user_agent}\n",
    "        r = requests.get(url, headers=headers)\n",
    "        \n",
    "        soup = BeautifulSoup(r.text)\n",
    "        \n",
    "        with open(\"logs/log.txt\", \"a\") as myfile:\n",
    "            myfile.write(url+'\\n')\n",
    "        \n",
    "        fap = soup.find('div', {'class': 'item-params'})\n",
    "        if fap is not None:           \n",
    "            li = fap.findAll('li', {'class':'item-params-list-item'})\n",
    "            for l in li:\n",
    "                full_app_dict[l.text.split(':')[0].strip()] = l.text.split(':')[1].strip()\n",
    "            full_app_dict['address'] = check_for_none(soup.find('div', {'class':'item-address'}))\n",
    "            full_app_dict['full_text_app'] = check_for_none(soup.find('div', class_=re.compile('item-description')))\n",
    "\n",
    "            ########################################################################\n",
    "            # Дополенная информация об объекте\n",
    "            adv_info = {}\n",
    "\n",
    "            fap_adv = soup.find('ul', class_=re.compile('advanced-params'))\n",
    "            if fap_adv is not None:\n",
    "                li = fap_adv.findAll('li', {'class': 'advanced-params-param'})\n",
    "                for l in li:\n",
    "                    param_list = []\n",
    "                    title = l.find('div', {'class': 'advanced-params-param-title'}).text\n",
    "                    item_list = l.find('ul', {'class': 'advanced-params-param-list'})  \n",
    "                    for il in item_list.findAll('li', {'class': 'advanced-params-param-item'}):\n",
    "                            param_list.append(il.text)    \n",
    "                    adv_info[title] = param_list\n",
    "\n",
    "            ########################################################################\n",
    "            #Дополнительная информация по цене в объявлении  \n",
    "            add_price = {}\n",
    "\n",
    "            js = soup.find('div', class_ = re.compile('js-ssr'))\n",
    "            if js is not None:    \n",
    "                add_info = json.loads(js['data-props'])\n",
    "                add_price['title'] = add_info['title']\n",
    "                add_price['subtitle'] = add_info['subtitle']\n",
    "                add_price['priceType'] = add_info['priceType']\n",
    "                add_price['marketPrice'] = add_info['marketPrice']\n",
    "                add_price['isVisibleForUser'] = add_info['isVisibleForUser']\n",
    "                add_price['price'] = add_info['price']\n",
    "            else:\n",
    "                add_price['title'] = ''\n",
    "                add_price['subtitle'] = ''\n",
    "                add_price['priceType'] = ''\n",
    "                add_price['marketPrice'] = ''\n",
    "                add_price['isVisibleForUser'] = ''\n",
    "                add_price['price'] = ''\n",
    "\n",
    "            ########################################################################\n",
    "            # Технические характеритики модели\n",
    "            spec_table = {}\n",
    "            spec_link = soup.find('a', {'class': 'item-view-specification-link'}, href=True)\n",
    "            if spec_link is not None:\n",
    "                url = main_url + spec_link['href']\n",
    "                user_agent = get_random_ua()\n",
    "                headers = { 'user-agent': user_agent}\n",
    "                r = requests.get(url,headers=headers)\n",
    "                soup = BeautifulSoup(r.text)\n",
    "                table = soup.findAll('table', class_=re.compile('specification-table'))\n",
    "                for tab in table:\n",
    "                    tr = tab.findAll('tr')\n",
    "                    for t in tr:\n",
    "                        td = t.findAll('td')\n",
    "                        spec_table[td[0].text] = td[1].text\n",
    "\n",
    "            # Собираем все данныe в один DataFrame\n",
    "            final_data.append({**spec_table, **add_price, **pred_ap, **adv_info, **full_app_dict})\n",
    "        else:\n",
    "            continue\n",
    "    pd.DataFrame(final_data).to_excel('data/avito/page'+str(i)+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avito Parsing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
